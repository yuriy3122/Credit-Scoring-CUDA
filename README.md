# CUDA MLP Binary Classifier for Mortgage Creditworthiness

This project implements a **CUDA-accelerated Multilayer Perceptron (MLP)** for **binary classification**, designed to estimate the **creditworthiness of loan applicants** using historical HMDA-like datasets and macroeconomic indicators.

It is a **pure C++/CUDA** implementation â€” no Python or PyTorch required â€” featuring a oneâ€‘hiddenâ€‘layer neural network trained directly on GPU with stochastic gradient descent (SGD).

---

## ğŸ“˜ Table of Contents

1. [Overview](#overview)  
2. [Dataset & Assumptions](#dataset--assumptions)  
3. [Model Architecture](#model-architecture)  
4. [Implementation Details](#implementation-details)  
5. [Build Instructions](#build-instructions)  
6. [Running the Model](#running-the-model)  
7. [Command-Line Arguments](#command-line-arguments)  
8. [Output Example](#output-example)
---

## ğŸ§¾ Overview

The model estimates whether a loan application is **creditworthy (1)** or **nonâ€‘creditworthy (0)** based on historical applicant data and macroeconomic factors.

It automatically:
- Parses a CSV dataset with headers,
- Detects numeric feature columns (skipping `"Exempt"` / empty values),
- Applies **Minâ€‘Max scaling** per feature,
- Splits into **70% training / 30% testing**,
- Trains an MLP (1 hidden layer, ReLU â†’ Sigmoid),
- Prints final **accuracy** on the test set.

---

## ğŸ“Š Dataset & Assumptions

Default expectations (override via CLI):
| Item | Description |
|------|-------------|
| **Target column** | `action_taken` |
| **Positive class** | `1` â†’ Approved / Creditworthy |
| **Negative class** | all other values |
| **Ignored values** | `"Exempt"`, empty cells |
| **Numeric detection** | Automatically selects up to 14 numeric columns |
| **Scaling** | Minâ€‘Max normalization per feature |

> You can change `--target`, `--features`, and RNG `--seed`.

---

## ğŸ§® Model Architecture

### ASCII Diagram

```
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚                 Input Features                â”‚
               â”‚      x âˆˆ â„^D  (scaled with Minâ€‘Max)           â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â”‚  Linear:  Zâ‚ = Wâ‚Â·x + bâ‚   (Wâ‚ âˆˆ â„^{HÃ—D})
                               â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚        ReLU          â”‚
                      â”‚  Aâ‚ = max(0, Zâ‚)     â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â”‚  Linear:  zâ‚‚ = Wâ‚‚Â·Aâ‚ + bâ‚‚  (Wâ‚‚ âˆˆ â„^{1Ã—H})
                                â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚       Sigmoid        â”‚
                      â”‚    Å· = Ïƒ(zâ‚‚) âˆˆ [0,1] â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                         Prediction âˆˆ {0,1}
                    (threshold at Å· â‰¥ 0.5 â†’ 1)
```

## âš™ï¸ Implementation Details

All computations are implemented with **custom CUDA kernels**:
| Function | Kernel | Description |
|---------|--------|-------------|
| Forward pass | `matmul`, `add_bias_relu`, `sigmoid_inplace` | Dense layers + activations |
| Backprop | `bce_dz2`, `relu_backward`, `matmul_AT_B` | Gradients for BCE + ReLU |
| Optimizer | `sgd_update` | Parameter updates |
| Utilities | `reduce_cols_mean`, `outer_product`, `scale_inplace` | Reductions & helpers |

> For production speed, swap naive matmuls with cuBLAS GEMM; add miniâ€‘batches and Adam.

---

## ğŸ› ï¸ Build Instructions

### Requirements
- **CUDA Toolkit 11+**
- **CMake 3.18+**
- **C++17** compiler (GCC/Clang/MSVC)

### Steps
```bash
cd cuda_mlp_binary
mkdir build && cd build
cmake ..
cmake --build . -j
```

---

## ğŸš€ Running the Model

```bash
./mlp_cuda --csv /path/to/train-hmda-data.csv \
           --epochs 200 \
           --lr 0.05 \
           --hidden 32 \
           --features 14 \
           --target action_taken
```

**Output example**
```
Loaded N=45000 D=14 from train-hmda-data.csv
Epoch 1/200 done
Epoch 25/200 done
...
Test accuracy: 0.864
```

---

## âš™ï¸ Command-Line Arguments

| Argument | Default | Description |
|---------|---------|-------------|
| `--csv PATH` | *(required)* | Path to input CSV |
| `--target NAME` | `action_taken` | Target column name |
| `--features N` | `14` | Max numeric columns to include |
| `--epochs N` | `200` | Number of training epochs |
| `--hidden H` | `32` | Hidden layer width |
| `--lr LR` | `0.05` | Learning rate (SGD) |
| `--seed S` | `5` | Random seed |

---

## ğŸ§  Output Example

After training, the model performs inference on the test split and prints:

```
Test accuracy: 0.8653
```
